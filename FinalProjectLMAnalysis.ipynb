{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4pueZw0BCO6"
   },
   "source": [
    "Mount Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHxPZ_Y9VD6p"
   },
   "source": [
    "Following the steps to create environment.\n",
    "1. start google colab and then open this notebook.\n",
    "2. clone the github codebase and pull the newest commits\n",
    "3. install environment\n",
    "4. run notebook in colab with GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHQ3h_aLAuEk"
   },
   "outputs": [],
   "source": [
    "# step2. clone github code base and pull\n",
    "\n",
    "!git clone https://github.com/CodeAlgorilla/llm-transparency-tool.git\n",
    "\n",
    "# checkout file directory\n",
    "%cd '/content/llm-transparency-tool'\n",
    "\n",
    "!git checkout ColabWorking  # checkout to your branch.\n",
    "!git pull --rebase origin ColabWorking # pull newest changes from your branch.\n",
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wOaUyZfKjqu"
   },
   "source": [
    "environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1ndoAmPDOOt"
   },
   "outputs": [],
   "source": [
    "# install python 3.10 for environment\n",
    "#!sudo apt-get install python3.10\n",
    "\n",
    "# install dependencies\n",
    "#!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2Hpu7aDMfg5"
   },
   "source": [
    "Import python modules and login huggingface with token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Z9Jt2YXMYoY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1rFh4h4K1et"
   },
   "source": [
    "Check devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0uBaqfxCMeF"
   },
   "outputs": [],
   "source": [
    "# Check device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You are using device: %s\" % device)\n",
    "\n",
    "!cat /proc/cpuinfo | grep 'model name'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNJHg+ha0tlT1wPsNgebzzt",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
