{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4pueZw0BCO6"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHxPZ_Y9VD6p"
      },
      "source": [
        "Following the steps to create environment.\n",
        "1. start google colab and then open this notebook.\n",
        "2. clone the github codebase and pull the newest commits\n",
        "3. install environment\n",
        "4. run notebook in colab with GPU support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHQ3h_aLAuEk"
      },
      "outputs": [],
      "source": [
        "# step2. clone github code base and pull\n",
        "\n",
        "!git clone https://github.com/CodeAlgorilla/llm-transparency-tool.git\n",
        "\n",
        "# checkout file directory\n",
        "%cd '/content/llm-transparency-tool'\n",
        "\n",
        "!git checkout ColabWorking  # checkout to your branch.\n",
        "!git pull --rebase origin ColabWorking # pull newest changes from your branch.\n",
        "!git status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wOaUyZfKjqu"
      },
      "source": [
        "environment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1ndoAmPDOOt"
      },
      "outputs": [],
      "source": [
        "# install conda\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "# install dependencies\n",
        "#!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version\n",
        "# install from env.yaml\n",
        "%pwd\n",
        "%ls\n",
        "%cd llm-transparency-tool\n",
        "!conda env update -n base -f env.yaml\n"
      ],
      "metadata": {
        "id": "8jv4Mj2gy_-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "#!conda env list\n",
        "#!conda list --explicit\n",
        "!conda init\n",
        "!conda activate base\n",
        "!pip install -e .\n",
        "%cd /content/llm-transparency-tool/llm_transparency_tool/components/frontend\n",
        "!yarn install\n",
        "!yarn build"
      ],
      "metadata": {
        "id": "nqj-mAUSzgXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Hpu7aDMfg5"
      },
      "source": [
        "Import python modules and login huggingface with token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z9Jt2YXMYoY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#from huggingface_hub import notebook_login\n",
        "#notebook_login()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1rFh4h4K1et"
      },
      "source": [
        "Check devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0uBaqfxCMeF"
      },
      "outputs": [],
      "source": [
        "# Check device availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"You are using device: %s\" % device)\n",
        "\n",
        "!cat /proc/cpuinfo | grep 'model name'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/llm-transparency-tool/\n",
        "%pwd\n",
        "!streamlit run llm_transparency_tool/server/app.py -- config/local.json &>/content/logs.txt &\n"
      ],
      "metadata": {
        "id": "qtPwyKUf2dyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "GldF-mvM4kI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}